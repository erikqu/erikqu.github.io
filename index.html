<!DOCTYPE html>
<html>
	<head>
		<!--importing font(s)-->
		<link href="https://fonts.googleapis.com/css?family=Open+Sans:300|Roboto|Space Mono" rel="stylesheet">
		<title>Erik Quintanilla</title>
		<link rel="stylesheet" type="text/css" href="css/main.css">
	</head>
	<body>	<nav>
    		<ul id = "header">
        		<li style = "font-family: 'Space Mono', 'helvetica'; list-style: none; font-size: 60px;">/INDEX.html</a></li>
    		</ul>
    	</nav>
		<div class="container">
    		<div>
        		<h2>Erik Quintanilla</h2>
    		</div>
    		<ul id = "bio">

    			<li> I'm a junior in Computer Science  from the Illinois Institute of Technology.  I have heavy interests in computer vision and deep learning. 
					I've been programming for a while but I have a fling with Physics.  Feynman is a big inspiration of mine.</li>
					<br>
					I'm very excited about Nvidia's new RTX GPUs, but not everyone is.  Check out my Medium article:  <a href="https://medium.com/@erikqu/why-is-real-time-ray-tracing-a-big-deal-688b79287325" style = "font-size: 12pt">Why is Ray Tracing a Big Deal?</a>

       		</ul>
    		<h2>Projects</h2>
    		<ul>
				    <li class = "post"> <p class = "postname"> Personalized Image Tagging </p>
					Over the summer of 2018 I had the amazing opportunity to do research at the University of Central Florida at CRCV under Dr. Mubarak Shah and Dr. Yogesh Rawat.  We developed a model here shown below that would take past 
					user history into account when generating image tags for a given image.  
					<br>
					This in turn gives us better image labels. I will first delve into some highlights about the project and then get into specifics about the model below. 
					<br>
					<br>
					<ul>
						<li> We made use of NUS-WIDE and YFCC100M, YFCC100M itself being ~1TB of image/user data.</li>
						<li> Since these datasets are based on Flickr, the user data was retrieved manually for every user.</li>
						<li> This is the first time deep learning is used to condense user preferences to generate image labels. </li>
						<li> Provides scalable solution for generating tags using deep learning. </li>
						<li> Adversarial learning used in the process, making use of a discriminator to generate better and better tags. </li>
						<li> ResNet-50 used as our main CNN here. </li>
						<li> Everything here was done mainly in Keras, although some of our earlier models made use of Caffe.</li>
					</ul>
						<br>
					<br> <img src = "screenshots/model.PNG"><br>
					    <br>
							<ul>
								<li> Once the user preferences gathered, these are encoded as vectors, and then depending on the frequency of the tag, the frequency is placed in the index corresponding to the tag. </li>
								<li> The Autoencoder then takes these in, and then the latent space representation is used to make our prediction since we want similar users to appear similar in order to avoid over-generalizing. </li>
								<li> Skip-connections are used in the Autoencoder for our reconstruction loss. </li>
								<li> We then repeat this condensed latent space representation from our Autoencoder to concatenate with the output of an intermediate convolution in order to take these preferences into account at every single pixel location. </li>
								<li> This is then fed into another small CNN that then generates our personalized image tags. </li>
								<li> The rest of ResNet just computes regular unpersonalized tags. </li>
								<li> <b>Accuracy of this model in Top-K, K@3, is 86% on NUS-WIDE.</b> Publication coming soon.. </li>
							</ul>
					    <br>
    				<br> <img src= "screenshots/tagging.PNG" ><br>
					
    				*Examples from NUS-WIDE 
    			</li>
    			<li class = "post"> <p class = "postname">WIREDSummarizer </p>
    				<br> <img src= "screenshots/wiredsum1.PNG" ><br><br>
    				I absolutely love everything about WIRED. But sometimes I don't have the time to read absolutely all the 
    				articles that I think are interesting, so I made WIREDSummarizer. Using textRank's NLP and some scraping techniques, I was
    				able to pull the text, treat it, and summarize it in 150 words or less!  This was also the first time I had actually run 
    				into code outside of class that ran so slow it would have to be treated with a little Cython.

    			</li>
    			<li class = "post"> <p class = "postname"> cryptoTicker </p>
    				<br> <img src= "screenshots/tickergui.PNG" ><br><br>
    				I wanted my first out of school project to be something that I was actually interested in, so I made it about crypto!
    				It auto-updates about every 20 seconds, and pulls the data from CoinMarketCap.  This was also the very first time I 
    				made an actual window for a program I've made.  I think it's great.  
    			</li>
    	</ul>
		</div>
		<footer>
    		<ul>
        		<li><a href="https://github.com/erikqu">Github</a></li>
        		<li><a href = "https://twitter.com/ErikQuintanito">Twitter</a></li>
        		<li><a href="mailto:eeerik8@gmail.com">Email</a></li>
			</ul>
		</footer>
	</body>
</html>
